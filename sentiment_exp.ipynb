{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-08T23:40:44.658909Z",
     "start_time": "2025-04-08T23:40:41.104449Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   ID   Timestamp                          Date     Query             User  \\\n0   0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  _TheSpecialOne_   \n1   0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY    scotthamilton   \n2   0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY         mattycus   \n3   0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY          ElleCTF   \n4   0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY           Karoli   \n\n                                               Tweet  Text  \n0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   NaN  \n1  is upset that he can't update his Facebook by ...   NaN  \n2  @Kenichan I dived many times for the ball. Man...   NaN  \n3    my whole body feels itchy and like its on fire    NaN  \n4  @nationwideclass no, it's not behaving at all....   NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Timestamp</th>\n      <th>Date</th>\n      <th>Query</th>\n      <th>User</th>\n      <th>Tweet</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1467810369</td>\n      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>_TheSpecialOne_</td>\n      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1467810672</td>\n      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>scotthamilton</td>\n      <td>is upset that he can't update his Facebook by ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1467810917</td>\n      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>mattycus</td>\n      <td>@Kenichan I dived many times for the ball. Man...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1467811184</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>ElleCTF</td>\n      <td>my whole body feels itchy and like its on fire</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>1467811193</td>\n      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Karoli</td>\n      <td>@nationwideclass no, it's not behaving at all....</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Download the latest version of the dataset\n",
    "path = kagglehub.dataset_download(\"kazanova/sentiment140\")\n",
    "\n",
    "# Find the CSV file in the directory\n",
    "file_path = None\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.csv'):  # Looking for .csv files\n",
    "        file_path = os.path.join(path, file)\n",
    "        break\n",
    "        \n",
    "column_names = ['ID', 'Timestamp', 'Date', 'Query', 'User', 'Tweet', 'Text']\n",
    "df = pd.read_csv(file_path, encoding='latin1', header=None, names=column_names)  # Use 'latin1' encoding if there are any encoding issues\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        ID   Timestamp                          Date     Query          User  \\\n150302   0  1898405077  Sat May 23 18:06:08 PDT 2009  NO_QUERY       Marcy_M   \n166174   0  1961175165  Fri May 29 09:05:52 PDT 2009  NO_QUERY    graceengle   \n172317   0  1963531905  Fri May 29 12:51:54 PDT 2009  NO_QUERY  alaskamiller   \n254812   0  1984340771  Sun May 31 14:55:05 PDT 2009  NO_QUERY         chimz   \n261218   0  1985862397  Sun May 31 17:54:51 PDT 2009  NO_QUERY       66Gia66   \n\n                                                    Tweet  Text  \n150302  @TeslaGirl360 This could have been us.    http...   NaN  \n166174  No launch today. Teacher changed plans and we ...   NaN  \n172317                 No one is at the tesla dealership    NaN  \n254812  @nluchs Hell yes.  They had a lot of cool thin...   NaN  \n261218  The Tesla coil in action made the boy start to...   NaN  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Timestamp</th>\n      <th>Date</th>\n      <th>Query</th>\n      <th>User</th>\n      <th>Tweet</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>150302</th>\n      <td>0</td>\n      <td>1898405077</td>\n      <td>Sat May 23 18:06:08 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>Marcy_M</td>\n      <td>@TeslaGirl360 This could have been us.    http...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>166174</th>\n      <td>0</td>\n      <td>1961175165</td>\n      <td>Fri May 29 09:05:52 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>graceengle</td>\n      <td>No launch today. Teacher changed plans and we ...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>172317</th>\n      <td>0</td>\n      <td>1963531905</td>\n      <td>Fri May 29 12:51:54 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>alaskamiller</td>\n      <td>No one is at the tesla dealership</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>254812</th>\n      <td>0</td>\n      <td>1984340771</td>\n      <td>Sun May 31 14:55:05 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>chimz</td>\n      <td>@nluchs Hell yes.  They had a lot of cool thin...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>261218</th>\n      <td>0</td>\n      <td>1985862397</td>\n      <td>Sun May 31 17:54:51 PDT 2009</td>\n      <td>NO_QUERY</td>\n      <td>66Gia66</td>\n      <td>The Tesla coil in action made the boy start to...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Separate plain words from hashtags and mentions\n",
    "plain_terms = ['Tesla', 'Lucid Motors', 'Rivian', 'Nikola', 'BYD', 'Polestar', 'ChargePoint',\n",
    "               'Electric Cars', 'Electric Vehicle', 'EV market']\n",
    "hashtag_terms = ['#Tesla', '#Lucid', '#Rivian', '#Nikola', '#BYDCompany', '#Polestar', '#ChargePoint', '#EV ', \n",
    "                 '#ElectricCar']\n",
    "mention_terms = ['@Tesla', '@Rivian', '@LucidMotors', '@ChargePoint', \n",
    "                 '@BYDCompany', '@NIOGlobal', '@ElectricVehicles']\n",
    "\n",
    "# Add word boundaries to plain terms\n",
    "plain_terms = [r'\\b' + re.escape(term) + r'\\b' for term in plain_terms]\n",
    "\n",
    "# Escape hashtags and mentions (they don't need word boundaries)\n",
    "hashtag_terms = [re.escape(term) for term in hashtag_terms]\n",
    "mention_terms = [re.escape(term) for term in mention_terms]\n",
    "\n",
    "# Combine all terms into a single regex pattern\n",
    "all_terms = plain_terms + hashtag_terms + mention_terms\n",
    "search_pattern = '|'.join(all_terms)\n",
    "\n",
    "# Filter the DataFrame\n",
    "df_filtered = df[df['Tweet'].str.contains(search_pattern, case=False, na=False, regex=True)]\n",
    "\n",
    "# Preview the results\n",
    "df_filtered.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T03:43:00.250790Z",
     "start_time": "2025-04-09T03:42:29.107507Z"
    }
   },
   "id": "3de8fde03e53e5b",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "array(['@TeslaGirl360 This could have been us.    http://bit.ly/oWZzF',\n       'No launch today. Teacher changed plans and we watched a stupid move about tesla ',\n       'No one is at the tesla dealership ',\n       \"@nluchs Hell yes.  They had a lot of cool things at Maker Faire SF yesterday but the singing tesla coils weren't there. \",\n       'The Tesla coil in action made the boy start to scream &amp; cry  &amp; we had to leave. http://yfrog.com/591bjj',\n       \"@teslaman2003 Haven't seen it.  Haven't really spent much time looking around online \",\n       'In Japan, Testing the Market for All-Electric Cars http://bit.ly/Qq2HW (via @markidea) they need to extend their range..for farther trip! ',\n       '@teslagold if only i had a car. your still moving to az??? ',\n       '@Teslanaut so most things then ',\n       \"Bernoulli &amp; Tesla: why do Bunsen get to be the picture?  we'z cute too!\",\n       '@teslaaa your such a procrastinator. the end. p.s i better see you before you leave! ',\n       '@teslaaa I already miss you. &lt;3 I wish I could have gone with you. Miss you ',\n       '@rt_winger I live by the Tesla dealership. Guys get their expensive Tesla cars and cruise University Avenue...I still get more attention! ',\n       \"clearing out &quot;My Received Folder.&quot; Loads of crap in there but also some absolute gems too. Hydrogen Nikola mix of 'Just Can't Get Enough' \",\n       '@ksmithington Tesla was raised with a cat in the house, he should know better! ',\n       '#SanctuarySunday hehe, tesla &amp; magnus.....very interesting chemistry  lol',\n       'Working in canberra on setting up a gpu cluster. Infiniband and tesla cards make it go fast (at least for some applications, anyway  )',\n       'Tesla Model S in the Palo Alto showroom - sweet ',\n       'Maker Faire. Yeah. Wow. Physics-Ferris-wheel funnelcake Tesla coils Adam Savage! Steampunk Exploratorium EepyBird metal and fire madness! ',\n       \"@flowerncsu but in other news, I dream of electric cars. I'm really excited to see the new volt. One day, I will be able to afford one. \",\n       \"@GraphicKarma The volt sounds like it will be very cool. Also, as long as we're dreaming, the tesla roadster. \",\n       'Also there was a TESLA COIL   #makerfaire  http://yfrog.com/59w1rj',\n       'A new #Lucid #dream Quest has been posted  Connect to a Source of Power http://bit.ly/YyRuU',\n       '@teslaman2003 Yep! You should come &amp; visit sometime ',\n       'Got to play with a tesla coil in physics class ',\n       'I thought auto manufacturers were shutting down dealerships, why is Tesla opening them?  http://tr.im/nzFO',\n       '@mrtech1 uuuuuuuhh niceeeeeee i made a project in college call the &quot;evolution of power&quot; nice tesla info today wupiiii  ',\n       '@bobbyllew wait til you get your tesla roadster. ',\n       '@bobbyllew It will be good test driving conditions to report back to Tesla Headquarters on how it performs under UK weather ',\n       '@tomsaxton Is that the Tesla that Grocophile built? ',\n       'and Tesla better hang out with me tomorrow since we have the same day off '],\n      dtype=object)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered['Tweet'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-09T03:44:34.839557Z",
     "start_time": "2025-04-09T03:44:34.802220Z"
    }
   },
   "id": "45bb4ac25513fe5b",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "# Set up Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id='WLlWYMAIAM2lYVJhucU9iQ',  # replace with your client_id\n",
    "    client_secret='wgsE_SCaXLtmwyefnFT1sOOZx0kkHA',  # replace with your client_secret\n",
    "    user_agent='EV Scraper by Zoe Tomlinson (contact: zoetomlinson@example.com)'  # more descriptive user-agent\n",
    ")\n",
    "\n",
    "# Define a single subreddit and simplified query to test\n",
    "subreddits = ['r/teslamotors']  # Test with just one subreddit first\n",
    "query = \"Tesla\"  # Simplified query for testing\n",
    "\n",
    "# List to store scraped posts\n",
    "posts = []\n",
    "\n",
    "# Scrape posts from the subreddit\n",
    "for subreddit in subreddits:\n",
    "    for submission in reddit.subreddit(subreddit).search(query, sort='new', limit=10):  # Limit to 10 posts for testing\n",
    "        # Check if 'selftext' is not empty\n",
    "        text = submission.selftext if submission.selftext else \"No text available\"\n",
    "        posts.append([submission.title, text, submission.score, submission.url, submission.subreddit, submission.created_utc])\n",
    "\n",
    "# Create a DataFrame from the scraped data\n",
    "df = pd.DataFrame(posts, columns=['Title', 'Text', 'Score', 'URL', 'Subreddit', 'Created UTC'])\n",
    "\n",
    "# Convert timestamps to readable date format\n",
    "df['Created UTC'] = pd.to_datetime(df['Created UTC'], unit='s')\n",
    "\n",
    "# Optionally, save the data to a CSV file\n",
    "df.to_csv('ev_posts.csv', index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fa5037383804fc4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
